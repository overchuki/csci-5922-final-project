{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:torchao.kernel.intmm:Warning: Detected no triton, on systems without Triton certain kernels will not work\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchtune\n",
    "import pickle as pkl\n",
    "\n",
    "from typing import Literal\n",
    "from dataclasses import dataclass\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from torchvision.transforms import v2\n",
    "from torchsummary import summary\n",
    "from torchmetrics.classification import MulticlassAccuracy, MulticlassPrecision, MulticlassRecall, MulticlassF1Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_DIM = 128\n",
    "NUM_CHANNELS = 3\n",
    "BATCH_SIZE = 512\n",
    "NORMALIZE_MEAN = (0.485,0.456,0.406)\n",
    "NORMALIZE_STD = (0.229,0.224,0.225)\n",
    "NUM_CLASSES = 90\n",
    "NUM_REAL_IMG_PER_CLASS = 60\n",
    "NUM_AI_IMG_PER_CLASS = 30\n",
    "REAL_IMG_TRAIN_PERCENTAGE = 0.5\n",
    "REAL_IMG_TEST_PERCENTAGE = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subset_indices(\n",
    "    num_img_per_class: int,\n",
    "    percent: float = 1.0,\n",
    "    side: Literal[\"left\", \"right\"] = \"left\",\n",
    ") -> np.ndarray:\n",
    "    indices = []\n",
    "    for i in range(NUM_CLASSES):\n",
    "        base = i * num_img_per_class\n",
    "        class_size = int(num_img_per_class * percent)\n",
    "        start = 0 if side == \"left\" else num_img_per_class - class_size\n",
    "        indices.extend(\n",
    "            list(np.arange(base + start, base + start + class_size))\n",
    "        )\n",
    "    return np.array(indices, dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loader(\n",
    "    real_img_dir: str = \"./real_animals\",\n",
    "    ai_img_dir: str = \"./ai_animals\",\n",
    "    real_img_percent: float = 1.0,\n",
    "    ai_img_percent: float = 0.0,\n",
    "    batch_size: int = BATCH_SIZE,\n",
    "    num_workers: int = 0,\n",
    "    shuffle: bool = True,\n",
    ") -> tuple[torch.utils.data.DataLoader, torch.utils.data.DataLoader]:\n",
    "    \"\"\"\n",
    "    Get train/test dataloaders for real and AI-generated images.\n",
    "    \"\"\"\n",
    "    transform = v2.Compose([\n",
    "        v2.Resize((IMG_DIM, IMG_DIM)),\n",
    "        v2.ToImage(),\n",
    "        v2.ToDtype(torch.float32, scale=True),\n",
    "        v2.Normalize(mean=NORMALIZE_MEAN, std=NORMALIZE_STD),\n",
    "    ])\n",
    "\n",
    "    train_real_img_subset = torch.utils.data.Subset(\n",
    "        torchvision.datasets.ImageFolder(\n",
    "            root=real_img_dir,\n",
    "            transform=transform,\n",
    "            allow_empty=True,\n",
    "        ),\n",
    "        indices=get_subset_indices(NUM_REAL_IMG_PER_CLASS, percent=REAL_IMG_TRAIN_PERCENTAGE * real_img_percent, side=\"left\"),\n",
    "    )\n",
    "    test_real_img_subset = torch.utils.data.Subset(\n",
    "        torchvision.datasets.ImageFolder(\n",
    "            root=real_img_dir,\n",
    "            transform=transform,\n",
    "            allow_empty=True,\n",
    "        ),\n",
    "        indices=get_subset_indices(NUM_REAL_IMG_PER_CLASS, percent=REAL_IMG_TEST_PERCENTAGE, side=\"right\"),\n",
    "    )\n",
    "    ai_img_subset = torch.utils.data.Subset(\n",
    "        torchvision.datasets.ImageFolder(\n",
    "            root=ai_img_dir,\n",
    "            transform=transform,\n",
    "            allow_empty=True,\n",
    "        ),\n",
    "        indices=get_subset_indices(NUM_AI_IMG_PER_CLASS, percent=ai_img_percent, side=\"left\"),\n",
    "    )\n",
    "\n",
    "    train_dataset = torchtune.datasets.ConcatDataset(datasets=[train_real_img_subset, ai_img_subset]) if ai_img_percent > 0.0 else train_real_img_subset\n",
    "    train_img_dataloader = torch.utils.data.DataLoader(\n",
    "        dataset=train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        num_workers=num_workers,\n",
    "    )\n",
    "    test_img_dataloader = torch.utils.data.DataLoader(\n",
    "        dataset=test_real_img_subset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        num_workers=num_workers,\n",
    "    )\n",
    "\n",
    "    return train_img_dataloader, test_img_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, input_channels, n_classes):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        # set metadata\n",
    "        self.input_channels = input_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.FINAL_LAYER_SIZE = 4\n",
    "        self.final_layer_channels = 40\n",
    "        self.flatten_layer_size = self.final_layer_channels * self.FINAL_LAYER_SIZE * self.FINAL_LAYER_SIZE\n",
    "\n",
    "        # dropout layers\n",
    "        self.dropout50 = nn.Dropout(p=0.5)\n",
    "        self.dropout10 = nn.Dropout(p=0.1)\n",
    "\n",
    "        # set up layers\n",
    "        self.conv1 = nn.Conv2d(in_channels=input_channels, out_channels=8, kernel_size=3, padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3, padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv3 = nn.Conv2d(in_channels=16, out_channels=24, kernel_size=3, padding=1)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv4 = nn.Conv2d(in_channels=24, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv5 = nn.Conv2d(in_channels=32, out_channels=self.final_layer_channels, kernel_size=3, padding=1)\n",
    "        self.pool5 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(self.flatten_layer_size, 128)\n",
    "        self.fc2 = nn.Linear(128, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 1: conv -> pool\n",
    "        x = self.conv1(x)\n",
    "        x = self.dropout10(torch.nn.functional.leaky_relu(x))\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        # 2: conv -> pool\n",
    "        x = self.conv2(x)\n",
    "        x = self.dropout10(torch.nn.functional.leaky_relu(x))\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        # 3: conv -> pool\n",
    "        x = self.conv3(x)\n",
    "        x = self.dropout10(torch.nn.functional.leaky_relu(x))\n",
    "        x = self.pool3(x)\n",
    "\n",
    "        # 4: conv -> pool\n",
    "        x = self.conv4(x)\n",
    "        x = self.dropout10(torch.nn.functional.leaky_relu(x))\n",
    "        x = self.pool4(x)\n",
    "\n",
    "        # 5: conv -> pool\n",
    "        x = self.conv5(x)\n",
    "        x = self.dropout10(torch.nn.functional.leaky_relu(x))\n",
    "        x = self.pool5(x)\n",
    "\n",
    "        # flatten the features (the first dimension is batch size)\n",
    "        x = x.view(-1, self.flatten_layer_size)\n",
    "\n",
    "        # fc layers\n",
    "        x = self.dropout50(torch.nn.functional.leaky_relu(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [512, 8, 128, 128]             224\n",
      "           Dropout-2         [512, 8, 128, 128]               0\n",
      "         MaxPool2d-3           [512, 8, 64, 64]               0\n",
      "            Conv2d-4          [512, 16, 64, 64]           1,168\n",
      "           Dropout-5          [512, 16, 64, 64]               0\n",
      "         MaxPool2d-6          [512, 16, 32, 32]               0\n",
      "            Conv2d-7          [512, 24, 32, 32]           3,480\n",
      "           Dropout-8          [512, 24, 32, 32]               0\n",
      "         MaxPool2d-9          [512, 24, 16, 16]               0\n",
      "           Conv2d-10          [512, 32, 16, 16]           6,944\n",
      "          Dropout-11          [512, 32, 16, 16]               0\n",
      "        MaxPool2d-12            [512, 32, 8, 8]               0\n",
      "           Conv2d-13            [512, 40, 8, 8]          11,560\n",
      "          Dropout-14            [512, 40, 8, 8]               0\n",
      "        MaxPool2d-15            [512, 40, 4, 4]               0\n",
      "           Linear-16                 [512, 128]          82,048\n",
      "          Dropout-17                 [512, 128]               0\n",
      "           Linear-18                  [512, 90]          11,610\n",
      "================================================================\n",
      "Total params: 117,034\n",
      "Trainable params: 117,034\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 96.00\n",
      "Forward/backward pass size (MB): 2039.85\n",
      "Params size (MB): 0.45\n",
      "Estimated Total Size (MB): 2136.30\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(CNN(input_channels=3, n_classes=NUM_CLASSES).to(device), (3, IMG_DIM, IMG_DIM), batch_size=BATCH_SIZE, device=device.type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombinedResNet50(nn.Module):\n",
    "    def __init__(self, input_channels, n_classes):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        # set metadata\n",
    "        self.input_channels = input_channels\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(CombinedResNet50(input_channels=3, n_classes=NUM_CLASSES).to(device), (3, IMG_DIM, IMG_DIM), batch_size=BATCH_SIZE, device=device.type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Result:\n",
    "    train_losses: list[float]\n",
    "    avg_train_accuracies: list[float]\n",
    "    test_losses: list[float]\n",
    "    test_accuracies: np.ndarray\n",
    "    avg_test_accuracies: list[float]\n",
    "    test_precision: np.ndarray\n",
    "    test_recall: np.ndarray\n",
    "    test_f1score: np.ndarray\n",
    "    avg_test_precision: float\n",
    "    avg_test_recall: float\n",
    "    avg_test_f1score: float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_basic_results(result: Result):\n",
    "    print(f\"Train Loss: {result.train_losses[-1]}\")\n",
    "    print(f\"Train Accuracy: {result.avg_train_accuracies[-1] * 100}%\\n\")\n",
    "    print(f\"Test Loss: {result.test_losses[-1]}\")\n",
    "    print(f\"Test Accuracy: {result.avg_test_accuracies[-1] * 100}%\\n\")\n",
    "    print(f\"Test Precision: {result.avg_test_precision * 100}%\")\n",
    "    print(f\"Test Recall: {result.avg_test_recall * 100}%\")\n",
    "    print(f\"Test F1 Score: {result.avg_test_f1score * 100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_accuracy(result: Result) -> None:\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(16, 4))\n",
    "    fig.subplots_adjust(wspace=0.4)\n",
    "\n",
    "    ax[0].set_title(\"Loss\")\n",
    "    ax[0].set_xlabel(\"Epoch\")\n",
    "    ax[0].plot(result.train_losses, label=\"Train Loss\", color=\"blue\")\n",
    "    ax[0].plot(result.test_losses, label=\"Test Loss\", color=\"red\")\n",
    "    ax[0].legend()\n",
    "    ax[0].set_ylabel(\"Cross Entropy Loss\")\n",
    "    ax[0].grid(axis=\"both\", linestyle=\"--\", alpha=0.7)\n",
    "\n",
    "    ax[1].set_title(\"Accuracy\")\n",
    "    ax[1].set_xlabel(\"Epoch\")\n",
    "    ax[1].plot(np.array(result.avg_train_accuracies)*100, label=\"Train Accuracy\", color=\"blue\")\n",
    "    ax[1].plot(np.array(result.avg_test_accuracies)*100, label=\"Test Accuracy\", color=\"red\")\n",
    "    ax[1].legend()\n",
    "    ax[1].set_ylabel(\"Accuracy (%)\")\n",
    "    ax[1].grid(axis=\"both\", linestyle=\"--\", alpha=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_improvement_by_class(\n",
    "    result_left: Result,\n",
    "    result_right: Result,\n",
    "    metric: str,\n",
    "    classes: list[str],\n",
    "    title: str = \"Changes by Class\",\n",
    "    multiply_by: float = 1.0,\n",
    ") -> None:\n",
    "    # metric can be \"test_accuracies\", \"test_precision\", \"test_recall\", \"test_f1score\"\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(16, 4))\n",
    "\n",
    "    diffs = np.array(result_right.__getattribute__(metric) - result_left.__getattribute__(metric))*multiply_by\n",
    "    sorted_indices = np.argsort(diffs)\n",
    "    diffs = diffs[sorted_indices]\n",
    "    classes = np.array(classes)[sorted_indices]\n",
    "\n",
    "    mask_positive = diffs >= 0\n",
    "    mask_negative = diffs < 0\n",
    "\n",
    "    negative = ax.bar(classes[mask_negative], diffs[mask_negative], color=\"red\")\n",
    "    ax.bar_label(negative, np.round(diffs[mask_negative], decimals=1), label_type=\"edge\", rotation=90)\n",
    "    \n",
    "    positive = ax.bar(classes[mask_positive], diffs[mask_positive], color=\"green\")\n",
    "    ax.bar_label(positive, np.round(diffs[mask_positive], decimals=1), label_type=\"edge\", rotation=90)\n",
    "\n",
    "    ax.tick_params(axis='x', labelrotation=90)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"Class\")\n",
    "    ax.set_ylabel(f\"Change in {metric.replace('_', ' ').title()}\")\n",
    "\n",
    "    diff_range = max(diffs) - min(diffs)\n",
    "    ax.set_ylim(bottom=min(diffs) - 0.2*diff_range, top=max(diffs) + 0.2*diff_range)\n",
    "    ax.axhline(0, color=\"black\", lw=1, ls=\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_diff_barchart(results: dict[str, Result]) -> None:\n",
    "    # bar chart showing performance in each desired metric for each group of results using the str key as a name\n",
    "    metrics = {\n",
    "        \"Train Loss\": {\n",
    "            \"key\": \"train_losses\",\n",
    "            \"get_value\": lambda x: x[-1],\n",
    "        },\n",
    "        \"Train Accuracy (%)\": {\n",
    "            \"key\": \"avg_train_accuracies\",\n",
    "            \"get_value\": lambda x: x[-1]*100.0,\n",
    "        },\n",
    "        \"Test Loss\": {\n",
    "            \"key\": \"test_losses\",\n",
    "            \"get_value\": lambda x: x[-1],\n",
    "        },\n",
    "        \"Test Accuracy (%)\": {\n",
    "            \"key\": \"avg_test_accuracies\",\n",
    "            \"get_value\": lambda x: x[-1]*100.0,\n",
    "        },\n",
    "        \"Test Precision (%)\": {\n",
    "            \"key\": \"avg_test_precision\",\n",
    "            \"get_value\": lambda x: x*100.0,\n",
    "        },\n",
    "        \"Test Recall (%)\": {\n",
    "            \"key\": \"avg_test_recall\",\n",
    "            \"get_value\": lambda x: x*100.0,\n",
    "        },\n",
    "        \"Test F1 Score (%)\": {\n",
    "            \"key\": \"avg_test_f1score\",\n",
    "            \"get_value\": lambda x: x*100.0,\n",
    "        }\n",
    "    }\n",
    "\n",
    "    metric_names = list(metrics.keys())\n",
    "    x = np.arange(len(metrics))\n",
    "    total_width = 0.5\n",
    "    width = total_width / len(results)\n",
    "    offsets = np.linspace(-total_width/2, total_width/2, len(results))\n",
    "    values = {}\n",
    "    max_value = 0.0\n",
    "    for result_name, result in results.items():\n",
    "        for _, metric in metrics.items():\n",
    "            if result_name not in values:\n",
    "                values[result_name] = []\n",
    "            value = metric[\"get_value\"](result.__getattribute__(metric[\"key\"]))\n",
    "            values[result_name].append(value)\n",
    "            if value > max_value:\n",
    "                max_value = value\n",
    "\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(16, 4))\n",
    "    for i, result_name in enumerate(values):\n",
    "        bars = ax.bar(x + offsets[i], values[result_name], width, label=result_name)\n",
    "        ax.bar_label(bars, np.round(values[result_name], decimals=1), label_type=\"edge\", rotation=90)\n",
    "\n",
    "    ax.tick_params(axis='x', labelrotation=45)\n",
    "    ax.set_title(\"Comparison of Results by Metric\")\n",
    "    ax.set_xlabel(\"Metric\")\n",
    "    ax.set_ylabel(\"Percent or Loss Depending on Metric\")\n",
    "    ax.set_xticks(x, metric_names)\n",
    "    ax.legend()\n",
    "    ax.set_ylim(bottom=0, top=max_value + 0.2*max_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test_model(\n",
    "        model: nn.Module,\n",
    "        optimizer: optim.Optimizer,\n",
    "        train_loader: torch.utils.data.DataLoader,\n",
    "        test_loader: torch.utils.data.DataLoader,\n",
    "        E: int,\n",
    "        verbose: Literal[\"none\", \"prints\", \"epoch_tqdm\", \"loader_tqdm\"] = \"epoch_tqdm\",\n",
    "    ) -> Result:\n",
    "    \"\"\"\n",
    "    Train and test the given model with the given parameters.\n",
    "    \"\"\"\n",
    "    loss_function = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "    accuracy_metric = MulticlassAccuracy(average='none', num_classes=NUM_CLASSES).to(device)\n",
    "    precision_metric = MulticlassPrecision(average='none', num_classes=NUM_CLASSES).to(device)\n",
    "    recall_metric = MulticlassRecall(average='none', num_classes=NUM_CLASSES).to(device)\n",
    "    f1_metric = MulticlassF1Score(average='none', num_classes=NUM_CLASSES).to(device)\n",
    "\n",
    "    train_losses = []\n",
    "    avg_train_accuracies = []\n",
    "    test_losses = []\n",
    "    test_accuracies = 0\n",
    "    avg_test_accuracies = []\n",
    "    test_precision = 0\n",
    "    test_recall = 0\n",
    "    test_f1score = 0\n",
    "    avg_test_precision = 0\n",
    "    avg_test_recall = 0\n",
    "    avg_test_f1score = 0\n",
    "\n",
    "    for epoch in tqdm(range(E), total=E, disable=verbose!=\"epoch_tqdm\"):\n",
    "        # TRAINING\n",
    "        model.train()\n",
    "        batch_losses = []\n",
    "        accuracy_metric.reset()\n",
    "        for images, labels in tqdm(train_loader, total=len(train_loader), disable=verbose!=\"loader_tqdm\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = loss_function(outputs, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            batch_losses.append(loss.item())\n",
    "            accuracy_metric.update(outputs, labels)\n",
    "        train_loss = np.mean(np.array(batch_losses))\n",
    "        train_losses.append(train_loss)\n",
    "        train_acc = accuracy_metric.compute()\n",
    "        avg_train_accuracies.append(train_acc.mean().item())\n",
    "\n",
    "        # TESTING\n",
    "        model.eval()\n",
    "        test_batch_losses = []\n",
    "        accuracy_metric.reset()\n",
    "        precision_metric.reset()\n",
    "        recall_metric.reset()\n",
    "        for images, labels in tqdm(test_loader, total=len(test_loader), disable=verbose!=\"loader_tqdm\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            test_batch_losses.append(loss_function(outputs, labels).item())\n",
    "            accuracy_metric.update(outputs, labels)\n",
    "            if epoch >= E - 1:\n",
    "                precision_metric.update(outputs, labels)\n",
    "                recall_metric.update(outputs, labels)\n",
    "                f1_metric.update(outputs, labels)\n",
    "        test_loss = np.mean(np.array(test_batch_losses))\n",
    "        test_losses.append(test_loss)\n",
    "        test_acc = accuracy_metric.compute()\n",
    "        avg_test_accuracies.append(test_acc.mean().item())\n",
    "        if epoch >= E - 1:\n",
    "            test_accuracies = test_acc.cpu().numpy()\n",
    "            test_precision = precision_metric.compute().cpu().numpy()\n",
    "            test_recall = recall_metric.compute().cpu().numpy()\n",
    "            test_f1score = f1_metric.compute().cpu().numpy()\n",
    "            avg_test_precision = test_precision.mean().item()\n",
    "            avg_test_recall = test_recall.mean().item()\n",
    "            avg_test_f1score = test_f1score.mean().item()\n",
    "\n",
    "        if verbose==\"prints\":\n",
    "            print(f\"Epoch [{epoch+1}/{E}]: Train Accuracy: {avg_train_accuracies[-1]*100:.2f}%, Train Loss: {train_loss:.4f}, Test Accuracy: {avg_test_accuracies[-1]*100:.2f}%, Test Loss: {test_loss:.4f}\")\n",
    "\n",
    "    print(f\"\\nEvaluation results:\\nTrain Accuracy: {avg_train_accuracies[-1]*100:.2f}%, Train Loss: {train_loss:.4f}\\nTest Accuracy: {avg_test_accuracies[-1]*100:.2f}%, Test Loss: {test_loss:.4f}\")\n",
    "\n",
    "    return Result(\n",
    "        train_losses=train_losses,\n",
    "        avg_train_accuracies=avg_train_accuracies,\n",
    "        test_losses=test_losses,\n",
    "        test_accuracies=test_accuracies,\n",
    "        avg_test_accuracies=avg_test_accuracies,\n",
    "        test_precision=test_precision,\n",
    "        test_recall=test_recall,\n",
    "        test_f1score=test_f1score,\n",
    "        avg_test_precision=avg_test_precision,\n",
    "        avg_test_recall=avg_test_recall,\n",
    "        avg_test_f1score=avg_test_f1score,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, test_loader = get_loader(real_img_percent=1.0, ai_img_percent=0.0, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [37:41<00:00, 45.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation results:\n",
      "Train Accuracy: 37.26%, Train Loss: 2.3609\n",
      "Test Accuracy: 14.85%, Test Loss: 4.1641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_params = {\n",
    "    \"name\": \"cnn_tune\",\n",
    "    \"learning_rate\": 0.0075,\n",
    "    \"weight_decay\": 0.0001,\n",
    "    \"epochs\": 50,\n",
    "}\n",
    "model = CNN(input_channels=NUM_CHANNELS, n_classes=NUM_CLASSES).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=model_params[\"learning_rate\"], weight_decay=model_params[\"weight_decay\"])\n",
    "results_1 = train_and_test_model(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    train_loader=train_loader,\n",
    "    test_loader=test_loader,\n",
    "    E=model_params[\"epochs\"],\n",
    "    verbose=\"epoch_tqdm\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"./results/{model_params[\"name\"]}_{model_params[\"epochs\"]}e_{str(model_params[\"learning_rate\"])[2:]}lr_{str(model_params[\"weight_decay\"])[2:]}wd.pkl\", \"wb\") as f:\n",
    "    pkl.dump(results_1, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
