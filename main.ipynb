{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchtune\n",
    "import pickle as pkl\n",
    "import os\n",
    "\n",
    "from typing import Literal, Any\n",
    "from tabulate import tabulate\n",
    "from dataclasses import dataclass\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from torchvision.transforms import v2\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "from torchsummary import summary\n",
    "from torchmetrics.classification import MulticlassAccuracy, MulticlassPrecision, MulticlassRecall, MulticlassF1Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_DIM = 128\n",
    "NUM_CHANNELS = 3\n",
    "BATCH_SIZE = 512\n",
    "NORMALIZE_MEAN = (0.485,0.456,0.406)\n",
    "NORMALIZE_STD = (0.229,0.224,0.225)\n",
    "NUM_CLASSES = 90\n",
    "NUM_REAL_IMG_PER_CLASS = 60\n",
    "NUM_AI_IMG_PER_CLASS = 30\n",
    "REAL_IMG_TRAIN_PERCENTAGE = 0.5\n",
    "REAL_IMG_TEST_PERCENTAGE = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subset_indices(\n",
    "    num_img_per_class: int,\n",
    "    percent: float = 1.0,\n",
    "    side: Literal[\"left\", \"right\"] = \"left\",\n",
    ") -> np.ndarray:\n",
    "    indices = []\n",
    "    for i in range(NUM_CLASSES):\n",
    "        base = i * num_img_per_class\n",
    "        class_size = int(num_img_per_class * percent)\n",
    "        start = 0 if side == \"left\" else num_img_per_class - class_size\n",
    "        indices.extend(\n",
    "            list(np.arange(base + start, base + start + class_size))\n",
    "        )\n",
    "    return np.array(indices, dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loader(\n",
    "    real_img_dir: str = \"./real_animals\",\n",
    "    ai_img_dir: str = \"./ai_animals\",\n",
    "    real_img_percent: float = 1.0,\n",
    "    ai_img_percent: float = 0.0,\n",
    "    batch_size: int = BATCH_SIZE,\n",
    "    num_workers: int = 0,\n",
    "    shuffle: bool = True,\n",
    ") -> tuple[torch.utils.data.DataLoader, torch.utils.data.DataLoader]:\n",
    "    \"\"\"\n",
    "    Get train/test dataloaders for real and AI-generated images.\n",
    "    \"\"\"\n",
    "    transform = v2.Compose([\n",
    "        v2.Resize((IMG_DIM, IMG_DIM)),\n",
    "        v2.ToImage(),\n",
    "        v2.ToDtype(torch.float32, scale=True),\n",
    "        v2.Normalize(mean=NORMALIZE_MEAN, std=NORMALIZE_STD),\n",
    "    ])\n",
    "\n",
    "    train_real_img_subset = torch.utils.data.Subset(\n",
    "        torchvision.datasets.ImageFolder(\n",
    "            root=real_img_dir,\n",
    "            transform=transform,\n",
    "            allow_empty=True,\n",
    "        ),\n",
    "        indices=get_subset_indices(NUM_REAL_IMG_PER_CLASS, percent=REAL_IMG_TRAIN_PERCENTAGE * real_img_percent, side=\"left\"),\n",
    "    )\n",
    "    test_real_img_subset = torch.utils.data.Subset(\n",
    "        torchvision.datasets.ImageFolder(\n",
    "            root=real_img_dir,\n",
    "            transform=transform,\n",
    "            allow_empty=True,\n",
    "        ),\n",
    "        indices=get_subset_indices(NUM_REAL_IMG_PER_CLASS, percent=REAL_IMG_TEST_PERCENTAGE, side=\"right\"),\n",
    "    )\n",
    "    ai_img_subset = torch.utils.data.Subset(\n",
    "        torchvision.datasets.ImageFolder(\n",
    "            root=ai_img_dir,\n",
    "            transform=transform,\n",
    "            allow_empty=True,\n",
    "        ),\n",
    "        indices=get_subset_indices(NUM_AI_IMG_PER_CLASS, percent=ai_img_percent, side=\"left\"),\n",
    "    )\n",
    "\n",
    "    train_dataset = torchtune.datasets.ConcatDataset(datasets=[train_real_img_subset, ai_img_subset]) if ai_img_percent > 0.0 else train_real_img_subset\n",
    "    train_img_dataloader = torch.utils.data.DataLoader(\n",
    "        dataset=train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        num_workers=num_workers,\n",
    "    )\n",
    "    test_img_dataloader = torch.utils.data.DataLoader(\n",
    "        dataset=test_real_img_subset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        num_workers=num_workers,\n",
    "    )\n",
    "\n",
    "    return train_img_dataloader, test_img_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models\n",
    "\n",
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, input_channels, n_classes):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        # set metadata\n",
    "        self.input_channels = input_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.FINAL_LAYER_SIZE = 4\n",
    "        self.final_layer_channels = 40\n",
    "        self.flatten_layer_size = self.final_layer_channels * self.FINAL_LAYER_SIZE * self.FINAL_LAYER_SIZE\n",
    "\n",
    "        # dropout layers\n",
    "        self.dropout50 = nn.Dropout(p=0.5)\n",
    "        self.dropout10 = nn.Dropout(p=0.1)\n",
    "\n",
    "        # set up layers\n",
    "        self.conv1 = nn.Conv2d(in_channels=input_channels, out_channels=8, kernel_size=3, padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3, padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv3 = nn.Conv2d(in_channels=16, out_channels=24, kernel_size=3, padding=1)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv4 = nn.Conv2d(in_channels=24, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv5 = nn.Conv2d(in_channels=32, out_channels=self.final_layer_channels, kernel_size=3, padding=1)\n",
    "        self.pool5 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(self.flatten_layer_size, 128)\n",
    "        self.fc2 = nn.Linear(128, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 1: conv -> pool\n",
    "        x = self.conv1(x)\n",
    "        x = self.dropout10(torch.nn.functional.leaky_relu(x))\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        # 2: conv -> pool\n",
    "        x = self.conv2(x)\n",
    "        x = self.dropout10(torch.nn.functional.leaky_relu(x))\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        # 3: conv -> pool\n",
    "        x = self.conv3(x)\n",
    "        x = self.dropout10(torch.nn.functional.leaky_relu(x))\n",
    "        x = self.pool3(x)\n",
    "\n",
    "        # 4: conv -> pool\n",
    "        x = self.conv4(x)\n",
    "        x = self.dropout10(torch.nn.functional.leaky_relu(x))\n",
    "        x = self.pool4(x)\n",
    "\n",
    "        # 5: conv -> pool\n",
    "        x = self.conv5(x)\n",
    "        x = self.dropout10(torch.nn.functional.leaky_relu(x))\n",
    "        x = self.pool5(x)\n",
    "\n",
    "        # flatten the features (the first dimension is batch size)\n",
    "        x = x.view(-1, self.flatten_layer_size)\n",
    "\n",
    "        # fc layers\n",
    "        x = self.dropout50(torch.nn.functional.leaky_relu(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [512, 8, 128, 128]             224\n",
      "           Dropout-2         [512, 8, 128, 128]               0\n",
      "         MaxPool2d-3           [512, 8, 64, 64]               0\n",
      "            Conv2d-4          [512, 16, 64, 64]           1,168\n",
      "           Dropout-5          [512, 16, 64, 64]               0\n",
      "         MaxPool2d-6          [512, 16, 32, 32]               0\n",
      "            Conv2d-7          [512, 24, 32, 32]           3,480\n",
      "           Dropout-8          [512, 24, 32, 32]               0\n",
      "         MaxPool2d-9          [512, 24, 16, 16]               0\n",
      "           Conv2d-10          [512, 32, 16, 16]           6,944\n",
      "          Dropout-11          [512, 32, 16, 16]               0\n",
      "        MaxPool2d-12            [512, 32, 8, 8]               0\n",
      "           Conv2d-13            [512, 40, 8, 8]          11,560\n",
      "          Dropout-14            [512, 40, 8, 8]               0\n",
      "        MaxPool2d-15            [512, 40, 4, 4]               0\n",
      "           Linear-16                 [512, 128]          82,048\n",
      "          Dropout-17                 [512, 128]               0\n",
      "           Linear-18                  [512, 90]          11,610\n",
      "================================================================\n",
      "Total params: 117,034\n",
      "Trainable params: 117,034\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 96.00\n",
      "Forward/backward pass size (MB): 2039.85\n",
      "Params size (MB): 0.45\n",
      "Estimated Total Size (MB): 2136.30\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(CNN(input_channels=3, n_classes=NUM_CLASSES).to(device), (3, IMG_DIM, IMG_DIM), batch_size=BATCH_SIZE, device=device.type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combined Pre-trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CombinedResNet50(frozen: bool = False) -> nn.Module:\n",
    "    model = resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "    if frozen:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "    model.fc = nn.Linear(2048, NUM_CLASSES)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [512, 64, 64, 64]           9,408\n",
      "       BatchNorm2d-2          [512, 64, 64, 64]             128\n",
      "              ReLU-3          [512, 64, 64, 64]               0\n",
      "         MaxPool2d-4          [512, 64, 32, 32]               0\n",
      "            Conv2d-5          [512, 64, 32, 32]           4,096\n",
      "       BatchNorm2d-6          [512, 64, 32, 32]             128\n",
      "              ReLU-7          [512, 64, 32, 32]               0\n",
      "            Conv2d-8          [512, 64, 32, 32]          36,864\n",
      "       BatchNorm2d-9          [512, 64, 32, 32]             128\n",
      "             ReLU-10          [512, 64, 32, 32]               0\n",
      "           Conv2d-11         [512, 256, 32, 32]          16,384\n",
      "      BatchNorm2d-12         [512, 256, 32, 32]             512\n",
      "           Conv2d-13         [512, 256, 32, 32]          16,384\n",
      "      BatchNorm2d-14         [512, 256, 32, 32]             512\n",
      "             ReLU-15         [512, 256, 32, 32]               0\n",
      "       Bottleneck-16         [512, 256, 32, 32]               0\n",
      "           Conv2d-17          [512, 64, 32, 32]          16,384\n",
      "      BatchNorm2d-18          [512, 64, 32, 32]             128\n",
      "             ReLU-19          [512, 64, 32, 32]               0\n",
      "           Conv2d-20          [512, 64, 32, 32]          36,864\n",
      "      BatchNorm2d-21          [512, 64, 32, 32]             128\n",
      "             ReLU-22          [512, 64, 32, 32]               0\n",
      "           Conv2d-23         [512, 256, 32, 32]          16,384\n",
      "      BatchNorm2d-24         [512, 256, 32, 32]             512\n",
      "             ReLU-25         [512, 256, 32, 32]               0\n",
      "       Bottleneck-26         [512, 256, 32, 32]               0\n",
      "           Conv2d-27          [512, 64, 32, 32]          16,384\n",
      "      BatchNorm2d-28          [512, 64, 32, 32]             128\n",
      "             ReLU-29          [512, 64, 32, 32]               0\n",
      "           Conv2d-30          [512, 64, 32, 32]          36,864\n",
      "      BatchNorm2d-31          [512, 64, 32, 32]             128\n",
      "             ReLU-32          [512, 64, 32, 32]               0\n",
      "           Conv2d-33         [512, 256, 32, 32]          16,384\n",
      "      BatchNorm2d-34         [512, 256, 32, 32]             512\n",
      "             ReLU-35         [512, 256, 32, 32]               0\n",
      "       Bottleneck-36         [512, 256, 32, 32]               0\n",
      "           Conv2d-37         [512, 128, 32, 32]          32,768\n",
      "      BatchNorm2d-38         [512, 128, 32, 32]             256\n",
      "             ReLU-39         [512, 128, 32, 32]               0\n",
      "           Conv2d-40         [512, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-41         [512, 128, 16, 16]             256\n",
      "             ReLU-42         [512, 128, 16, 16]               0\n",
      "           Conv2d-43         [512, 512, 16, 16]          65,536\n",
      "      BatchNorm2d-44         [512, 512, 16, 16]           1,024\n",
      "           Conv2d-45         [512, 512, 16, 16]         131,072\n",
      "      BatchNorm2d-46         [512, 512, 16, 16]           1,024\n",
      "             ReLU-47         [512, 512, 16, 16]               0\n",
      "       Bottleneck-48         [512, 512, 16, 16]               0\n",
      "           Conv2d-49         [512, 128, 16, 16]          65,536\n",
      "      BatchNorm2d-50         [512, 128, 16, 16]             256\n",
      "             ReLU-51         [512, 128, 16, 16]               0\n",
      "           Conv2d-52         [512, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-53         [512, 128, 16, 16]             256\n",
      "             ReLU-54         [512, 128, 16, 16]               0\n",
      "           Conv2d-55         [512, 512, 16, 16]          65,536\n",
      "      BatchNorm2d-56         [512, 512, 16, 16]           1,024\n",
      "             ReLU-57         [512, 512, 16, 16]               0\n",
      "       Bottleneck-58         [512, 512, 16, 16]               0\n",
      "           Conv2d-59         [512, 128, 16, 16]          65,536\n",
      "      BatchNorm2d-60         [512, 128, 16, 16]             256\n",
      "             ReLU-61         [512, 128, 16, 16]               0\n",
      "           Conv2d-62         [512, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-63         [512, 128, 16, 16]             256\n",
      "             ReLU-64         [512, 128, 16, 16]               0\n",
      "           Conv2d-65         [512, 512, 16, 16]          65,536\n",
      "      BatchNorm2d-66         [512, 512, 16, 16]           1,024\n",
      "             ReLU-67         [512, 512, 16, 16]               0\n",
      "       Bottleneck-68         [512, 512, 16, 16]               0\n",
      "           Conv2d-69         [512, 128, 16, 16]          65,536\n",
      "      BatchNorm2d-70         [512, 128, 16, 16]             256\n",
      "             ReLU-71         [512, 128, 16, 16]               0\n",
      "           Conv2d-72         [512, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-73         [512, 128, 16, 16]             256\n",
      "             ReLU-74         [512, 128, 16, 16]               0\n",
      "           Conv2d-75         [512, 512, 16, 16]          65,536\n",
      "      BatchNorm2d-76         [512, 512, 16, 16]           1,024\n",
      "             ReLU-77         [512, 512, 16, 16]               0\n",
      "       Bottleneck-78         [512, 512, 16, 16]               0\n",
      "           Conv2d-79         [512, 256, 16, 16]         131,072\n",
      "      BatchNorm2d-80         [512, 256, 16, 16]             512\n",
      "             ReLU-81         [512, 256, 16, 16]               0\n",
      "           Conv2d-82           [512, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-83           [512, 256, 8, 8]             512\n",
      "             ReLU-84           [512, 256, 8, 8]               0\n",
      "           Conv2d-85          [512, 1024, 8, 8]         262,144\n",
      "      BatchNorm2d-86          [512, 1024, 8, 8]           2,048\n",
      "           Conv2d-87          [512, 1024, 8, 8]         524,288\n",
      "      BatchNorm2d-88          [512, 1024, 8, 8]           2,048\n",
      "             ReLU-89          [512, 1024, 8, 8]               0\n",
      "       Bottleneck-90          [512, 1024, 8, 8]               0\n",
      "           Conv2d-91           [512, 256, 8, 8]         262,144\n",
      "      BatchNorm2d-92           [512, 256, 8, 8]             512\n",
      "             ReLU-93           [512, 256, 8, 8]               0\n",
      "           Conv2d-94           [512, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-95           [512, 256, 8, 8]             512\n",
      "             ReLU-96           [512, 256, 8, 8]               0\n",
      "           Conv2d-97          [512, 1024, 8, 8]         262,144\n",
      "      BatchNorm2d-98          [512, 1024, 8, 8]           2,048\n",
      "             ReLU-99          [512, 1024, 8, 8]               0\n",
      "      Bottleneck-100          [512, 1024, 8, 8]               0\n",
      "          Conv2d-101           [512, 256, 8, 8]         262,144\n",
      "     BatchNorm2d-102           [512, 256, 8, 8]             512\n",
      "            ReLU-103           [512, 256, 8, 8]               0\n",
      "          Conv2d-104           [512, 256, 8, 8]         589,824\n",
      "     BatchNorm2d-105           [512, 256, 8, 8]             512\n",
      "            ReLU-106           [512, 256, 8, 8]               0\n",
      "          Conv2d-107          [512, 1024, 8, 8]         262,144\n",
      "     BatchNorm2d-108          [512, 1024, 8, 8]           2,048\n",
      "            ReLU-109          [512, 1024, 8, 8]               0\n",
      "      Bottleneck-110          [512, 1024, 8, 8]               0\n",
      "          Conv2d-111           [512, 256, 8, 8]         262,144\n",
      "     BatchNorm2d-112           [512, 256, 8, 8]             512\n",
      "            ReLU-113           [512, 256, 8, 8]               0\n",
      "          Conv2d-114           [512, 256, 8, 8]         589,824\n",
      "     BatchNorm2d-115           [512, 256, 8, 8]             512\n",
      "            ReLU-116           [512, 256, 8, 8]               0\n",
      "          Conv2d-117          [512, 1024, 8, 8]         262,144\n",
      "     BatchNorm2d-118          [512, 1024, 8, 8]           2,048\n",
      "            ReLU-119          [512, 1024, 8, 8]               0\n",
      "      Bottleneck-120          [512, 1024, 8, 8]               0\n",
      "          Conv2d-121           [512, 256, 8, 8]         262,144\n",
      "     BatchNorm2d-122           [512, 256, 8, 8]             512\n",
      "            ReLU-123           [512, 256, 8, 8]               0\n",
      "          Conv2d-124           [512, 256, 8, 8]         589,824\n",
      "     BatchNorm2d-125           [512, 256, 8, 8]             512\n",
      "            ReLU-126           [512, 256, 8, 8]               0\n",
      "          Conv2d-127          [512, 1024, 8, 8]         262,144\n",
      "     BatchNorm2d-128          [512, 1024, 8, 8]           2,048\n",
      "            ReLU-129          [512, 1024, 8, 8]               0\n",
      "      Bottleneck-130          [512, 1024, 8, 8]               0\n",
      "          Conv2d-131           [512, 256, 8, 8]         262,144\n",
      "     BatchNorm2d-132           [512, 256, 8, 8]             512\n",
      "            ReLU-133           [512, 256, 8, 8]               0\n",
      "          Conv2d-134           [512, 256, 8, 8]         589,824\n",
      "     BatchNorm2d-135           [512, 256, 8, 8]             512\n",
      "            ReLU-136           [512, 256, 8, 8]               0\n",
      "          Conv2d-137          [512, 1024, 8, 8]         262,144\n",
      "     BatchNorm2d-138          [512, 1024, 8, 8]           2,048\n",
      "            ReLU-139          [512, 1024, 8, 8]               0\n",
      "      Bottleneck-140          [512, 1024, 8, 8]               0\n",
      "          Conv2d-141           [512, 512, 8, 8]         524,288\n",
      "     BatchNorm2d-142           [512, 512, 8, 8]           1,024\n",
      "            ReLU-143           [512, 512, 8, 8]               0\n",
      "          Conv2d-144           [512, 512, 4, 4]       2,359,296\n",
      "     BatchNorm2d-145           [512, 512, 4, 4]           1,024\n",
      "            ReLU-146           [512, 512, 4, 4]               0\n",
      "          Conv2d-147          [512, 2048, 4, 4]       1,048,576\n",
      "     BatchNorm2d-148          [512, 2048, 4, 4]           4,096\n",
      "          Conv2d-149          [512, 2048, 4, 4]       2,097,152\n",
      "     BatchNorm2d-150          [512, 2048, 4, 4]           4,096\n",
      "            ReLU-151          [512, 2048, 4, 4]               0\n",
      "      Bottleneck-152          [512, 2048, 4, 4]               0\n",
      "          Conv2d-153           [512, 512, 4, 4]       1,048,576\n",
      "     BatchNorm2d-154           [512, 512, 4, 4]           1,024\n",
      "            ReLU-155           [512, 512, 4, 4]               0\n",
      "          Conv2d-156           [512, 512, 4, 4]       2,359,296\n",
      "     BatchNorm2d-157           [512, 512, 4, 4]           1,024\n",
      "            ReLU-158           [512, 512, 4, 4]               0\n",
      "          Conv2d-159          [512, 2048, 4, 4]       1,048,576\n",
      "     BatchNorm2d-160          [512, 2048, 4, 4]           4,096\n",
      "            ReLU-161          [512, 2048, 4, 4]               0\n",
      "      Bottleneck-162          [512, 2048, 4, 4]               0\n",
      "          Conv2d-163           [512, 512, 4, 4]       1,048,576\n",
      "     BatchNorm2d-164           [512, 512, 4, 4]           1,024\n",
      "            ReLU-165           [512, 512, 4, 4]               0\n",
      "          Conv2d-166           [512, 512, 4, 4]       2,359,296\n",
      "     BatchNorm2d-167           [512, 512, 4, 4]           1,024\n",
      "            ReLU-168           [512, 512, 4, 4]               0\n",
      "          Conv2d-169          [512, 2048, 4, 4]       1,048,576\n",
      "     BatchNorm2d-170          [512, 2048, 4, 4]           4,096\n",
      "            ReLU-171          [512, 2048, 4, 4]               0\n",
      "      Bottleneck-172          [512, 2048, 4, 4]               0\n",
      "AdaptiveAvgPool2d-173          [512, 2048, 1, 1]               0\n",
      "          Linear-174                  [512, 90]         184,410\n",
      "================================================================\n",
      "Total params: 23,692,442\n",
      "Trainable params: 184,410\n",
      "Non-trainable params: 23,508,032\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 96.00\n",
      "Forward/backward pass size (MB): 15144.35\n",
      "Params size (MB): 90.38\n",
      "Estimated Total Size (MB): 15330.73\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\igort\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchsummary\\torchsummary.py:93: RuntimeWarning: overflow encountered in scalar add\n",
      "  total_output += np.prod(summary[layer][\"output_shape\"])\n"
     ]
    }
   ],
   "source": [
    "summary(CombinedResNet50(True).to(device), (3, IMG_DIM, IMG_DIM), batch_size=BATCH_SIZE, device=device.type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Result:\n",
    "    train_losses: list[float]\n",
    "    avg_train_accuracies: list[float]\n",
    "    test_losses: list[float]\n",
    "    test_accuracies: np.ndarray\n",
    "    avg_test_accuracies: list[float]\n",
    "    test_precision: np.ndarray\n",
    "    test_recall: np.ndarray\n",
    "    test_f1score: np.ndarray\n",
    "    avg_test_precision: float\n",
    "    avg_test_recall: float\n",
    "    avg_test_f1score: float\n",
    "\n",
    "DIFF_METRICS = {\n",
    "    \"Train Accuracy\": {\n",
    "        \"key\": \"avg_train_accuracies\",\n",
    "        \"get_value\": lambda x: x[-1]*100.0,\n",
    "    },\n",
    "    \"Test Accuracy\": {\n",
    "        \"key\": \"avg_test_accuracies\",\n",
    "        \"get_value\": lambda x: x[-1]*100.0,\n",
    "    },\n",
    "    \"Test Precision\": {\n",
    "        \"key\": \"avg_test_precision\",\n",
    "        \"get_value\": lambda x: x*100.0,\n",
    "    },\n",
    "    \"Test Recall\": {\n",
    "        \"key\": \"avg_test_recall\",\n",
    "        \"get_value\": lambda x: x*100.0,\n",
    "    },\n",
    "    \"Test F1 Score\": {\n",
    "        \"key\": \"avg_test_f1score\",\n",
    "        \"get_value\": lambda x: x*100.0,\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Result Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_result(model_params: dict, with_details: bool = True) -> Result:\n",
    "    details = f\"_{model_params[\"epochs\"]}e_{str(model_params[\"learning_rate\"])[2:]}lr_{str(model_params[\"weight_decay\"])[2:]}wd\" if with_details else \"\"\n",
    "    with open(f\"./results/{model_params[\"name\"]}{details}.pkl\", \"rb\") as f:\n",
    "        result = pkl.load(f)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_result(result: Result, model_params: dict, with_details: bool = True) -> None:\n",
    "    details = f\"_{model_params[\"epochs\"]}e_{str(model_params[\"learning_rate\"])[2:]}lr_{str(model_params[\"weight_decay\"])[2:]}wd\" if with_details else \"\"\n",
    "    filepath = f\"./results/{model_params[\"name\"]}{details}.pkl\"\n",
    "    if os.path.isfile(filepath):\n",
    "        print(\"Error: File already exists, not overwriting.\")\n",
    "        return\n",
    "    with open(filepath, \"wb\") as f:\n",
    "        pkl.dump(result, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_basic_results(result: Result):\n",
    "    print(f\"Train Loss: {result.train_losses[-1]}\")\n",
    "    print(f\"Train Accuracy: {result.avg_train_accuracies[-1] * 100}%\\n\")\n",
    "    print(f\"Test Loss: {result.test_losses[-1]}\")\n",
    "    print(f\"Test Accuracy: {result.avg_test_accuracies[-1] * 100}%\\n\")\n",
    "    print(f\"Test Precision: {result.avg_test_precision * 100}%\")\n",
    "    print(f\"Test Recall: {result.avg_test_recall * 100}%\")\n",
    "    print(f\"Test F1 Score: {result.avg_test_f1score * 100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_diff_table(results: dict[str, Result], title: str, metrics: dict[str, dict[str, Any]]) -> None:\n",
    "    metric_names = list(metrics.keys())\n",
    "    values = []\n",
    "    for result_name, result in results.items():\n",
    "        row_array = [result_name]\n",
    "        for _, metric in metrics.items():\n",
    "            value = str(np.round(metric[\"get_value\"](result.__getattribute__(metric[\"key\"])), decimals=4)) + \"%\"\n",
    "            row_array.append(value)\n",
    "        values.append(row_array)\n",
    "    print(tabulate(values, headers=metric_names, tablefmt=\"rounded_grid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_accuracy(result: Result) -> None:\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(16, 4))\n",
    "    fig.subplots_adjust(wspace=0.4)\n",
    "\n",
    "    ax[0].set_title(\"Loss\")\n",
    "    ax[0].set_xlabel(\"Epoch\")\n",
    "    ax[0].plot(result.train_losses, label=\"Train Loss\", color=\"blue\")\n",
    "    ax[0].plot(result.test_losses, label=\"Test Loss\", color=\"red\")\n",
    "    ax[0].legend()\n",
    "    ax[0].set_ylabel(\"Cross Entropy Loss\")\n",
    "    ax[0].grid(axis=\"both\", linestyle=\"--\", alpha=0.7)\n",
    "\n",
    "    ax[1].set_title(\"Accuracy\")\n",
    "    ax[1].set_xlabel(\"Epoch\")\n",
    "    ax[1].plot(np.array(result.avg_train_accuracies)*100, label=\"Train Accuracy\", color=\"blue\")\n",
    "    ax[1].plot(np.array(result.avg_test_accuracies)*100, label=\"Test Accuracy\", color=\"red\")\n",
    "    ax[1].legend()\n",
    "    ax[1].set_ylabel(\"Accuracy (%)\")\n",
    "    ax[1].grid(axis=\"both\", linestyle=\"--\", alpha=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_improvement_by_class(\n",
    "    result_left: Result,\n",
    "    result_right: Result,\n",
    "    metric: Literal[\"test_accuracies\", \"test_precision\", \"test_recall\", \"test_f1score\"],\n",
    "    classes: list[str],\n",
    "    title: str = \"Changes by Class\",\n",
    "    multiply_by: float = 1.0,\n",
    ") -> None:\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(16, 4))\n",
    "\n",
    "    diffs = np.array(result_right.__getattribute__(metric) - result_left.__getattribute__(metric))*multiply_by\n",
    "    sorted_indices = np.argsort(diffs)\n",
    "    diffs = diffs[sorted_indices]\n",
    "    classes = np.array(classes)[sorted_indices]\n",
    "\n",
    "    mask_positive = diffs >= 0\n",
    "    mask_negative = diffs < 0\n",
    "\n",
    "    negative = ax.bar(classes[mask_negative], diffs[mask_negative], color=\"red\")\n",
    "    ax.bar_label(negative, np.round(diffs[mask_negative], decimals=1), label_type=\"edge\", rotation=90)\n",
    "    \n",
    "    positive = ax.bar(classes[mask_positive], diffs[mask_positive], color=\"green\")\n",
    "    ax.bar_label(positive, np.round(diffs[mask_positive], decimals=1), label_type=\"edge\", rotation=90)\n",
    "\n",
    "    ax.tick_params(axis='x', labelrotation=90)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"Class\")\n",
    "    ax.set_ylabel(f\"Change in {metric.replace('_', ' ').title()}\")\n",
    "\n",
    "    diff_range = max(diffs) - min(diffs)\n",
    "    ax.set_ylim(bottom=min(diffs) - 0.2*diff_range, top=max(diffs) + 0.2*diff_range)\n",
    "    ax.axhline(0, color=\"black\", lw=1, ls=\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_diff_barchart(results: dict[str, Result], title: str, metrics: dict[str, dict[str, Any]]) -> None:\n",
    "    metric_names = list(metrics.keys())\n",
    "    x = np.arange(len(metrics))\n",
    "    total_width = 0.5\n",
    "    width = total_width / len(results)\n",
    "    extra_spacing = 0.05*total_width\n",
    "    offsets = np.linspace((-total_width/2) + (width/2) - extra_spacing, (total_width/2) - (width/2) + extra_spacing, len(results))\n",
    "    values = {}\n",
    "    max_value = 0.0\n",
    "    for result_name, result in results.items():\n",
    "        for _, metric in metrics.items():\n",
    "            if result_name not in values:\n",
    "                values[result_name] = []\n",
    "            value = metric[\"get_value\"](result.__getattribute__(metric[\"key\"]))\n",
    "            values[result_name].append(value)\n",
    "            if value > max_value:\n",
    "                max_value = value\n",
    "\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(16, 4))\n",
    "    for i, result_name in enumerate(values):\n",
    "        bars = ax.bar(x + offsets[i], values[result_name], width, label=result_name)\n",
    "        ax.bar_label(bars, np.round(values[result_name], decimals=1), label_type=\"edge\", rotation=90)\n",
    "\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"Metric\")\n",
    "    ax.set_ylabel(\"Percent (%)\")\n",
    "    ax.set_xticks(x, metric_names)\n",
    "    ax.legend(ncols=3)\n",
    "    ax.set_ylim(bottom=0, top=max_value + 0.2*max_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test_model(\n",
    "        model: nn.Module,\n",
    "        optimizer: optim.Optimizer,\n",
    "        train_loader: torch.utils.data.DataLoader,\n",
    "        test_loader: torch.utils.data.DataLoader,\n",
    "        E: int,\n",
    "        verbose: Literal[\"none\", \"prints\", \"epoch_tqdm\", \"loader_tqdm\"] = \"epoch_tqdm\",\n",
    "    ) -> Result:\n",
    "    \"\"\"\n",
    "    Train and test the given model with the given parameters.\n",
    "    \"\"\"\n",
    "    loss_function = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "    accuracy_metric = MulticlassAccuracy(average='none', num_classes=NUM_CLASSES).to(device)\n",
    "    precision_metric = MulticlassPrecision(average='none', num_classes=NUM_CLASSES).to(device)\n",
    "    recall_metric = MulticlassRecall(average='none', num_classes=NUM_CLASSES).to(device)\n",
    "    f1_metric = MulticlassF1Score(average='none', num_classes=NUM_CLASSES).to(device)\n",
    "\n",
    "    train_losses = []\n",
    "    avg_train_accuracies = []\n",
    "    test_losses = []\n",
    "    test_accuracies = 0\n",
    "    avg_test_accuracies = []\n",
    "    test_precision = 0\n",
    "    test_recall = 0\n",
    "    test_f1score = 0\n",
    "    avg_test_precision = 0\n",
    "    avg_test_recall = 0\n",
    "    avg_test_f1score = 0\n",
    "\n",
    "    for epoch in tqdm(range(E), total=E, disable=verbose!=\"epoch_tqdm\"):\n",
    "        # TRAINING\n",
    "        model.train()\n",
    "        batch_losses = []\n",
    "        accuracy_metric.reset()\n",
    "        for images, labels in tqdm(train_loader, total=len(train_loader), disable=verbose!=\"loader_tqdm\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = loss_function(outputs, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            batch_losses.append(loss.item())\n",
    "            accuracy_metric.update(outputs, labels)\n",
    "        train_loss = np.mean(np.array(batch_losses))\n",
    "        train_losses.append(train_loss)\n",
    "        train_acc = accuracy_metric.compute()\n",
    "        avg_train_accuracies.append(train_acc.mean().item())\n",
    "\n",
    "        # TESTING\n",
    "        model.eval()\n",
    "        test_batch_losses = []\n",
    "        accuracy_metric.reset()\n",
    "        precision_metric.reset()\n",
    "        recall_metric.reset()\n",
    "        for images, labels in tqdm(test_loader, total=len(test_loader), disable=verbose!=\"loader_tqdm\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            test_batch_losses.append(loss_function(outputs, labels).item())\n",
    "            accuracy_metric.update(outputs, labels)\n",
    "            if epoch >= E - 1:\n",
    "                precision_metric.update(outputs, labels)\n",
    "                recall_metric.update(outputs, labels)\n",
    "                f1_metric.update(outputs, labels)\n",
    "        test_loss = np.mean(np.array(test_batch_losses))\n",
    "        test_losses.append(test_loss)\n",
    "        test_acc = accuracy_metric.compute()\n",
    "        avg_test_accuracies.append(test_acc.mean().item())\n",
    "        if epoch >= E - 1:\n",
    "            test_accuracies = test_acc.cpu().numpy()\n",
    "            test_precision = precision_metric.compute().cpu().numpy()\n",
    "            test_recall = recall_metric.compute().cpu().numpy()\n",
    "            test_f1score = f1_metric.compute().cpu().numpy()\n",
    "            avg_test_precision = test_precision.mean().item()\n",
    "            avg_test_recall = test_recall.mean().item()\n",
    "            avg_test_f1score = test_f1score.mean().item()\n",
    "\n",
    "        if verbose==\"prints\":\n",
    "            print(f\"Epoch [{epoch+1}/{E}]: Train Accuracy: {avg_train_accuracies[-1]*100:.2f}%, Train Loss: {train_loss:.4f}, Test Accuracy: {avg_test_accuracies[-1]*100:.2f}%, Test Loss: {test_loss:.4f}\")\n",
    "\n",
    "    print(f\"\\nEvaluation results:\\nTrain Accuracy: {avg_train_accuracies[-1]*100:.2f}%, Train Loss: {train_loss:.4f}\\nTest Accuracy: {avg_test_accuracies[-1]*100:.2f}%, Test Loss: {test_loss:.4f}\")\n",
    "\n",
    "    return Result(\n",
    "        train_losses=train_losses,\n",
    "        avg_train_accuracies=avg_train_accuracies,\n",
    "        test_losses=test_losses,\n",
    "        test_accuracies=test_accuracies,\n",
    "        avg_test_accuracies=avg_test_accuracies,\n",
    "        test_precision=test_precision,\n",
    "        test_recall=test_recall,\n",
    "        test_f1score=test_f1score,\n",
    "        avg_test_precision=avg_test_precision,\n",
    "        avg_test_recall=avg_test_recall,\n",
    "        avg_test_f1score=avg_test_f1score,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, test_loader = get_loader(real_img_percent=1.0, ai_img_percent=0.0, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [17:04<00:00, 51.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation results:\n",
      "Train Accuracy: 99.81%, Train Loss: 0.2646\n",
      "Test Accuracy: 85.78%, Test Loss: 0.8424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_params = {\n",
    "    \"name\": \"combined_tune\",\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"weight_decay\": 0.001,\n",
    "    \"epochs\": 20,\n",
    "}\n",
    "model = CombinedResNet50(frozen=True).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=model_params[\"learning_rate\"], weight_decay=model_params[\"weight_decay\"])\n",
    "results_1 = train_and_test_model(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    train_loader=train_loader,\n",
    "    test_loader=test_loader,\n",
    "    E=model_params[\"epochs\"],\n",
    "    verbose=\"epoch_tqdm\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: File already exists, not overwriting.\n"
     ]
    }
   ],
   "source": [
    "save_result(results_1, model_params, with_details=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "**CNN Params**\n",
    "\n",
    "Learning Rate: `0.0001`;\n",
    "Weight Decay: `0.0075`;\n",
    "Epochs: `50`\n",
    "\n",
    "**Combined Pre-trained Params**\n",
    "\n",
    "Learning Rate: `0.001`;\n",
    "Weight Decay: `0.001`;\n",
    "Epochs: `20`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN_MODEL_PARAMS(name: str) -> dict:\n",
    "    return {\n",
    "        \"name\": f\"cnn_{name}\",\n",
    "        \"learning_rate\": 0.0075,\n",
    "        \"weight_decay\": 0.0001,\n",
    "        \"epochs\": 50,\n",
    "    }\n",
    "def COMBINED_MODEL_PARAMS(name: str) -> dict:\n",
    "    return {\n",
    "        \"name\": f\"combined_{name}\",\n",
    "        \"learning_rate\": 0.001,\n",
    "        \"weight_decay\": 0.001,\n",
    "        \"epochs\": 20,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, test_loader = get_loader(real_img_percent=0.5, ai_img_percent=1.0, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [57:23<00:00, 68.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation results:\n",
      "Train Accuracy: 49.11%, Train Loss: 1.7481\n",
      "Test Accuracy: 15.33%, Test Loss: 4.3343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cnn_model_params = CNN_MODEL_PARAMS(\"50real_100ai\")\n",
    "model = CNN(input_channels=NUM_CHANNELS, n_classes=NUM_CLASSES).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=cnn_model_params[\"learning_rate\"], weight_decay=cnn_model_params[\"weight_decay\"])\n",
    "cnn_result = train_and_test_model(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    train_loader=train_loader,\n",
    "    test_loader=test_loader,\n",
    "    E=cnn_model_params[\"epochs\"],\n",
    "    verbose=\"epoch_tqdm\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_result(cnn_result, cnn_model_params, with_details=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combined Pre-trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, test_loader = get_loader(real_img_percent=1.0, ai_img_percent=0.0, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [17:15<00:00, 51.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation results:\n",
      "Train Accuracy: 99.78%, Train Loss: 0.2537\n",
      "Test Accuracy: 85.48%, Test Loss: 0.8492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "combined_model_params = COMBINED_MODEL_PARAMS(\"100real_0ai\")\n",
    "model = CombinedResNet50(frozen=True).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=combined_model_params[\"learning_rate\"], weight_decay=combined_model_params[\"weight_decay\"])\n",
    "combined_result = train_and_test_model(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    train_loader=train_loader,\n",
    "    test_loader=test_loader,\n",
    "    E=combined_model_params[\"epochs\"],\n",
    "    verbose=\"epoch_tqdm\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_result(combined_result, combined_model_params, with_details=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [21:45<00:00, 65.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation results:\n",
      "Train Accuracy: 99.80%, Train Loss: 0.1950\n",
      "Test Accuracy: 86.30%, Test Loss: 0.7272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_loader, test_loader = get_loader(real_img_percent=1.0, ai_img_percent=0.5, num_workers=0)\n",
    "combined_model_params = COMBINED_MODEL_PARAMS(\"100real_50ai\")\n",
    "model = CombinedResNet50(frozen=True).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=combined_model_params[\"learning_rate\"], weight_decay=combined_model_params[\"weight_decay\"])\n",
    "combined_result = train_and_test_model(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    train_loader=train_loader,\n",
    "    test_loader=test_loader,\n",
    "    E=combined_model_params[\"epochs\"],\n",
    "    verbose=\"epoch_tqdm\",\n",
    ")\n",
    "save_result(combined_result, combined_model_params, with_details=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [27:13<00:00, 81.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation results:\n",
      "Train Accuracy: 99.83%, Train Loss: 0.1566\n",
      "Test Accuracy: 85.56%, Test Loss: 0.6924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_loader, test_loader = get_loader(real_img_percent=1.0, ai_img_percent=1.0, num_workers=0)\n",
    "combined_model_params = COMBINED_MODEL_PARAMS(\"100real_100ai\")\n",
    "model = CombinedResNet50(frozen=True).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=combined_model_params[\"learning_rate\"], weight_decay=combined_model_params[\"weight_decay\"])\n",
    "combined_result = train_and_test_model(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    train_loader=train_loader,\n",
    "    test_loader=test_loader,\n",
    "    E=combined_model_params[\"epochs\"],\n",
    "    verbose=\"epoch_tqdm\",\n",
    ")\n",
    "save_result(combined_result, combined_model_params, with_details=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [22:45<00:00, 68.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation results:\n",
      "Train Accuracy: 99.90%, Train Loss: 0.1704\n",
      "Test Accuracy: 80.93%, Test Loss: 0.8923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_loader, test_loader = get_loader(real_img_percent=0.5, ai_img_percent=1.0, num_workers=0)\n",
    "combined_model_params = COMBINED_MODEL_PARAMS(\"50real_100ai\")\n",
    "model = CombinedResNet50(frozen=True).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=combined_model_params[\"learning_rate\"], weight_decay=combined_model_params[\"weight_decay\"])\n",
    "combined_result = train_and_test_model(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    train_loader=train_loader,\n",
    "    test_loader=test_loader,\n",
    "    E=combined_model_params[\"epochs\"],\n",
    "    verbose=\"epoch_tqdm\",\n",
    ")\n",
    "save_result(combined_result, combined_model_params, with_details=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [18:36<00:00, 55.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation results:\n",
      "Train Accuracy: 99.96%, Train Loss: 0.1743\n",
      "Test Accuracy: 65.70%, Test Loss: 1.6780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_loader, test_loader = get_loader(real_img_percent=0.0, ai_img_percent=1.0, num_workers=0)\n",
    "combined_model_params = COMBINED_MODEL_PARAMS(\"0real_100ai\")\n",
    "model = CombinedResNet50(frozen=True).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=combined_model_params[\"learning_rate\"], weight_decay=combined_model_params[\"weight_decay\"])\n",
    "combined_result = train_and_test_model(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    train_loader=train_loader,\n",
    "    test_loader=test_loader,\n",
    "    E=combined_model_params[\"epochs\"],\n",
    "    verbose=\"epoch_tqdm\",\n",
    ")\n",
    "save_result(combined_result, combined_model_params, with_details=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
