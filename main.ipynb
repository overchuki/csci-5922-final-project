{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchtune\n",
    "\n",
    "from typing import Literal\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from torchvision.transforms import v2\n",
    "from torchsummary import summary\n",
    "from torchmetrics.classification import MulticlassAccuracy, MulticlassPrecision, MulticlassRecall, MulticlassF1Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_DIM = 256\n",
    "NUM_CHANNELS = 3\n",
    "BATCH_SIZE = 128\n",
    "NORMALIZE_MEAN = (0.485,0.456,0.406)\n",
    "NORMALIZE_STD = (0.229,0.224,0.225)\n",
    "NUM_CLASSES = 90\n",
    "NUM_REAL_IMG_PER_CLASS = 60\n",
    "REAL_IMG_TRAIN_PERCENTAGE = 0.5\n",
    "REAL_IMG_TEST_PERCENTAGE = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subset_indices(\n",
    "    percent: float = 1.0,\n",
    "    side: Literal[\"left\", \"right\"] = \"left\",\n",
    ") -> np.ndarray:\n",
    "    indices = []\n",
    "    for i in range(NUM_CLASSES):\n",
    "        base = i * NUM_REAL_IMG_PER_CLASS\n",
    "        class_size = int(NUM_REAL_IMG_PER_CLASS * percent)\n",
    "        start = 0 if side == \"left\" else NUM_REAL_IMG_PER_CLASS - class_size\n",
    "        indices.extend(\n",
    "            list(np.arange(base + start, base + start + class_size))\n",
    "        )\n",
    "    return np.array(indices, dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loader(\n",
    "    real_img_dir: str = \"./real_animals\",\n",
    "    ai_img_dir: str = \"./ai_animals\",\n",
    "    real_img_percent: float = 1.0,\n",
    "    ai_img_percent: float = 0.0,\n",
    "    batch_size: int = BATCH_SIZE,\n",
    "    num_workers: int = 0,\n",
    "    shuffle: bool = True,\n",
    ") -> tuple[torch.utils.data.DataLoader, torch.utils.data.DataLoader]:\n",
    "    \"\"\"\n",
    "    Get train/test dataloaders for real and AI-generated images.\n",
    "    \"\"\"\n",
    "    transform = v2.Compose([\n",
    "        v2.Resize((IMG_DIM, IMG_DIM)),\n",
    "        v2.ToImage(),\n",
    "        v2.ToDtype(torch.float32, scale=True),\n",
    "        v2.Normalize(mean=NORMALIZE_MEAN, std=NORMALIZE_STD),\n",
    "    ])\n",
    "\n",
    "    train_real_img_subset = torch.utils.data.Subset(\n",
    "        torchvision.datasets.ImageFolder(\n",
    "            root=real_img_dir,\n",
    "            transform=transform,\n",
    "            allow_empty=True,\n",
    "        ),\n",
    "        indices=get_subset_indices(percent=REAL_IMG_TRAIN_PERCENTAGE * real_img_percent, side=\"left\"),\n",
    "    )\n",
    "    test_real_img_subset = torch.utils.data.Subset(\n",
    "        torchvision.datasets.ImageFolder(\n",
    "            root=real_img_dir,\n",
    "            transform=transform,\n",
    "            allow_empty=True,\n",
    "        ),\n",
    "        indices=get_subset_indices(percent=REAL_IMG_TEST_PERCENTAGE, side=\"right\"),\n",
    "    )\n",
    "    ai_img_subset = torch.utils.data.Subset(\n",
    "        torchvision.datasets.ImageFolder(\n",
    "            root=ai_img_dir,\n",
    "            transform=transform,\n",
    "            allow_empty=True,\n",
    "        ),\n",
    "        indices=get_subset_indices(percent=ai_img_percent, side=\"left\"),\n",
    "    )\n",
    "\n",
    "    train_dataset = torchtune.datasets.ConcatDataset(datasets=[train_real_img_subset, ai_img_subset]) if ai_img_percent > 0.0 else train_real_img_subset\n",
    "    train_img_dataloader = torch.utils.data.DataLoader(\n",
    "        dataset=train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        num_workers=num_workers,\n",
    "    )\n",
    "    test_img_dataloader = torch.utils.data.DataLoader(\n",
    "        dataset=test_real_img_subset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        num_workers=num_workers,\n",
    "    )\n",
    "\n",
    "    return train_img_dataloader, test_img_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl, test_dl = get_loader(real_img_percent=1.0, ai_img_percent=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "class_counts = {}\n",
    "for img, label in train_dl:\n",
    "    i += 1\n",
    "    if i > 4:\n",
    "        break\n",
    "    print(img.shape, label.shape)\n",
    "#     for l in label:\n",
    "#         if l.item() not in class_counts:\n",
    "#             class_counts[l.item()] = 0\n",
    "#         class_counts[l.item()] += 1\n",
    "# print(class_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, input_channels, n_classes):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        # set metadata\n",
    "        self.input_channels = input_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.FINAL_LAYER_SIZE = 8\n",
    "        self.final_layer_channels = 40\n",
    "        self.flatten_layer_size = self.final_layer_channels * self.FINAL_LAYER_SIZE * self.FINAL_LAYER_SIZE\n",
    "\n",
    "        # dropout layer\n",
    "        self.dropout50 = nn.Dropout(p=0.5)\n",
    "        self.dropout10 = nn.Dropout(p=0.1)\n",
    "\n",
    "        # set up layers\n",
    "        self.conv1 = nn.Conv2d(in_channels=input_channels, out_channels=8, kernel_size=3, padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3, padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv3 = nn.Conv2d(in_channels=16, out_channels=24, kernel_size=3, padding=1)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv4 = nn.Conv2d(in_channels=24, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        # self.conv5 = nn.Conv2d(in_channels=32, out_channels=40, kernel_size=3, padding=1)\n",
    "        # self.pool5 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv5 = nn.Conv2d(in_channels=32, out_channels=self.final_layer_channels, kernel_size=3, padding=1)\n",
    "        self.pool5 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(self.flatten_layer_size, 128)\n",
    "        self.fc2 = nn.Linear(128, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 1: conv -> pool\n",
    "        x = self.conv1(x)\n",
    "        x = self.dropout10(torch.nn.functional.leaky_relu(x))\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        # 2: conv -> pool\n",
    "        x = self.conv2(x)\n",
    "        x = self.dropout10(torch.nn.functional.leaky_relu(x))\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        # 3: conv -> pool\n",
    "        x = self.conv3(x)\n",
    "        x = self.dropout10(torch.nn.functional.leaky_relu(x))\n",
    "        x = self.pool3(x)\n",
    "\n",
    "        # 4: conv -> pool\n",
    "        x = self.conv4(x)\n",
    "        x = self.dropout10(torch.nn.functional.leaky_relu(x))\n",
    "        x = self.pool4(x)\n",
    "\n",
    "        # 5: conv -> pool\n",
    "        x = self.conv5(x)\n",
    "        x = self.dropout10(torch.nn.functional.leaky_relu(x))\n",
    "        x = self.pool5(x)\n",
    "\n",
    "        # # 6: conv -> pool\n",
    "        # x = self.conv6(x)\n",
    "        # x = self.dropout10(torch.nn.functional.leaky_relu(x))\n",
    "        # x = self.pool6(x)\n",
    "\n",
    "        # flatten the features (the first dimension is batch size)\n",
    "        x = x.view(-1, self.flatten_layer_size)\n",
    "\n",
    "        # fc layers\n",
    "        x = self.dropout50(torch.nn.functional.leaky_relu(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(CNN(input_channels=3, n_classes=NUM_CLASSES).to(device), (3, IMG_DIM, IMG_DIM), batch_size=BATCH_SIZE, device=device.type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombinedResNet50(nn.Module):\n",
    "    def __init__(self, input_channels, n_classes):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        # set metadata\n",
    "        self.input_channels = input_channels\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(CombinedResNet50(input_channels=3, n_classes=NUM_CLASSES).to(device), (3, IMG_DIM, IMG_DIM), batch_size=BATCH_SIZE, device=device.type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_accuracy(results) -> None:\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(16, 4))\n",
    "    fig.subplots_adjust(wspace=0.4)\n",
    "\n",
    "    # ax[0].set_title(\"Loss\")\n",
    "    # ax[0].set_xlabel(\"Epoch\")\n",
    "    # ax[0].plot(results[0][0], label=\"Train Loss\", color=\"blue\")\n",
    "    # ax[0].plot(results[1][0], label=\"Test Loss\", color=\"red\")\n",
    "    # ax[0].legend()\n",
    "    # ax[0].set_ylabel(\"Cross Entropy Loss\")\n",
    "\n",
    "    # ax[1].set_title(\"Accuracy\")\n",
    "    # ax[1].set_xlabel(\"Epoch\")\n",
    "    # ax[1].plot(results[0][1], label=\"Train Accuracy\", color=\"blue\")\n",
    "    # ax[1].plot(results[1][1], label=\"Test Accuracy\", color=\"red\")\n",
    "    # ax[1].legend()\n",
    "    # ax[1].set_ylabel(\"Accuracy (%)\")\n",
    "\n",
    "    # ax[2].set_title(\"Precision and Recall\")\n",
    "    # ax[2].set_xlabel(\"Epoch\")\n",
    "    # ax[2].plot(results[2][0], label=\"Test Precision\", color=\"cyan\")\n",
    "    # ax[2].plot(results[2][1], label=\"Test Recall\", color=\"orange\")\n",
    "    # ax[2].legend()\n",
    "    # ax[2].set_ylabel(\"Precision/Recall Score (0-1)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_improvement_by_class(results) -> None:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_diff_barchart(results) -> None:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test_model(\n",
    "        model: nn.Module,\n",
    "        optimizer: optim.Optimizer,\n",
    "        train_loader: torch.utils.data.DataLoader,\n",
    "        test_loader: torch.utils.data.DataLoader,\n",
    "        E: int,\n",
    "        verbose: bool = True,\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Train and test the given model with the given parameters.\n",
    "    \"\"\"\n",
    "    # TODO: see if worth it\n",
    "    # model = torch.compile(model)\n",
    "    loss_function = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "    # TODO: switch accuracy to none\n",
    "    accuracy_metric = MulticlassAccuracy(average='micro', num_classes=NUM_CLASSES).to(device)\n",
    "    precision_metric = MulticlassPrecision(average='none', num_classes=NUM_CLASSES).to(device)\n",
    "    recall_metric = MulticlassRecall(average='none', num_classes=NUM_CLASSES).to(device)\n",
    "    f1_metric = MulticlassF1Score(average='none', num_classes=NUM_CLASSES).to(device)\n",
    "\n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "    test_losses = []\n",
    "    test_accuracies = []\n",
    "    test_precision = 0\n",
    "    test_recall = 0\n",
    "    test_f1score = 0\n",
    "\n",
    "    for epoch in range(E):\n",
    "        # TRAINING\n",
    "        model.train()\n",
    "        batch_losses = []\n",
    "        accuracy_metric.reset()\n",
    "        for images, labels in tqdm(train_loader, total=len(train_loader)):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = loss_function(outputs, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            batch_losses.append(loss.item())\n",
    "            accuracy_metric.update(outputs, labels)\n",
    "        train_loss = np.mean(np.array(batch_losses))\n",
    "        train_acc = accuracy_metric.compute().item()\n",
    "        train_losses.append(train_loss)\n",
    "        train_accuracies.append(train_acc)\n",
    "\n",
    "        # TESTING\n",
    "        model.eval()\n",
    "        test_batch_losses = []\n",
    "        accuracy_metric.reset()\n",
    "        precision_metric.reset()\n",
    "        recall_metric.reset()\n",
    "        for images, labels in tqdm(test_loader, total=len(test_loader)):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            test_batch_losses.append(loss_function(outputs, labels).item())\n",
    "            accuracy_metric.update(outputs, labels)\n",
    "            # if epoch >= E - 1:\n",
    "            #     precision_metric.update(outputs, labels)\n",
    "            #     recall_metric.update(outputs, labels)\n",
    "            #     f1_metric.update(outputs, labels)\n",
    "        test_loss = np.mean(np.array(test_batch_losses))\n",
    "        test_acc = accuracy_metric.compute().item()\n",
    "        test_losses.append(test_loss)\n",
    "        test_accuracies.append(test_acc)\n",
    "        # if epoch >= E - 1:\n",
    "        #     test_precision = precision_metric.compute().item()\n",
    "        #     test_recall = recall_metric.compute().item()\n",
    "        #     test_f1score = f1_metric.compute().item()\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Epoch [{epoch+1}/{E}]: Train Accuracy: {train_acc*100:.2f}%, Train Loss: {train_loss:.4f}, Test Accuracy: {test_acc*100:.2f}%, Test Loss: {test_loss:.4f}\")\n",
    "\n",
    "    print(f\"\\nEvaluation results:\\nTrain Accuracy: {train_acc*100:.2f}%, Train Loss: {train_loss:.4f}\\nTest Accuracy: {test_acc*100:.2f}%, Test Loss: {test_loss:.4f}\")\n",
    "\n",
    "    return 27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, test_loader = get_loader(real_img_percent=1.0, ai_img_percent=0.0, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN(input_channels=NUM_CHANNELS, n_classes=NUM_CLASSES).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "results_1 = train_and_test_model(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    train_loader=train_loader,\n",
    "    test_loader=test_loader,\n",
    "    E=1,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
